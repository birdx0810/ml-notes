# Generation

## Music Generation

1. Generating Long-Term Structure in Songs and Stories. Elliot Waite. [website](https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn)
2. This Time with Feeling: Learning Expressive Musical Performance. Sageev Oore, Ian Simon, Sander Dieleman, Douglas Eck, Karen Simonyan. [paper](https://arxiv.org/abs/1808.03715)
   * See also: PerformanceRNN: [website](https://magenta.tensorflow.org/performance-rnn)
3. Music Transformer: Generating Music with Long-Term Structure. Cheng-Zhi Anna Huang, Ashish Vaswani, Jakob Uszkoreit, Noam Shazeer, Ian Simon, Curtis Hawthorne, Andrew M. Dai, Matthew D. Hoffman, Monica Dinculescu, Douglas Eck. [paper](https://arxiv.org/abs/1809.04281)
4. Jukebox: A Generative Model for Music. Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever. [website](https://openai.com/blog/jukebox/)
   * See also: [Clara](http://christinemcleavey.com/clara-a-neural-net-music-generator/) and [MuseNet](https://openai.com/blog/musenet/)


## Speech Synthesis

### Autoregressive Models

1. WaveNet: A Generative Model for Raw Audio. Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, Koray Kavukcuoglu. ISCA Workshop 2016. [blog](https://deepmind.com/blog/article/wavenet-generative-model-raw-audio)
2. SampleRNN: An Unconditional End-to-End Neural Audio Generation Model. Soroush Mehri, Kundan Kumar, Ishaan Gulrajani, Rithesh Kumar, Shubham Jain, Jose Sotelo, Aaron Courville, Yoshua Bengio. ICLR 2017. [paper](https://arxiv.org/abs/1612.07837)
3. Char2Wav: End-to-End Speech Synthesis. Jose Sotelo, Soroush Mehri, Kundan Kumar, Jo√£o Felipe Santos, Kyle Kastner, Aaron Courville, Yoshua Bengio. ICLR 2017. [website](http://www.josesotelo.com/speechsynthesis/)
4. Tacotron: Towards End-to-End Speech Synthesis. [website](https://google.github.io/tacotron/)
5. WaveRNN: Efficient Neural Audio Synthesis. Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Norman Casagrande, Edward Lockhart, Florian Stimberg, Aaron van den Oord, Sander Dieleman, Koray Kavukcuoglu. ICML 2018. [paper](https://arxiv.org/abs/1802.08435)

### Non-autoregressive

1. Parallel WaveNet: Fast High-Fidelity Speech Synthesis. Aaron van den Oord, Yazhe Li, Igor Babuschkin, Karen Simonyan, Oriol Vinyals, Koray Kavukcuoglu, George van den Driessche, Edward Lockhart, Luis C. Cobo, Florian Stimberg, Norman Casagrande, Dominik Grewe, Seb Noury, Sander Dieleman, Erich Elsen, Nal Kalchbrenner, Heiga Zen, Alex Graves, Helen King, Tom Walters, Dan Belov, Demis Hassabis. ICML 2018. [paper](https://arxiv.org/abs/1711.10433)
2. ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech. Wei Ping, Kainan Peng, Jitong Chen. ICLR 2019. [paper](https://arxiv.org/abs/1807.07281)
3. WaveGlow: : A Flow-based Generative Network for Speech Synthesis. Ryan Prenger, Rafael Valle, Bryan Catanzaro. [paper](https://arxiv.org/abs/1811.00002)
4. FastSpeech: Fast, Robust and Controllable Text to Speech. Yi Ren, Yangjun Ruan, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu. [paper](https://arxiv.org/abs/1905.09263)

### Generative Adversarial Networks

## Other Links

* Frank Brinkkemper's [blog](https://www.asimovinstitute.org/analyzing-deep-learning-tools-music/) on 6 Deep Learning Tools for Music Generation
* ESPNet: End-to-end speech processing toolkit. [github](https://github.com/espnet/espnet)

